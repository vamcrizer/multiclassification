{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = np.load(\"X.npy\")\n",
    "    y = np.load(\"y.npy\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X ,y = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X is:  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.56059680e-06\n",
      "  1.94035948e-06 -7.37438725e-04 -8.13403799e-03 -1.86104473e-02\n",
      " -1.87412865e-02 -1.87572508e-02 -1.90963542e-02 -1.64039011e-02\n",
      " -3.78191381e-03  3.30347316e-04  1.27655229e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.16421569e-04  1.20052179e-04\n",
      " -1.40444581e-02 -2.84542484e-02  8.03826593e-02  2.66540339e-01\n",
      "  2.73853746e-01  2.78729541e-01  2.74293607e-01  2.24676403e-01\n",
      "  2.77562977e-02 -7.06315478e-03  2.34715414e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.28335523e-17 -3.26286765e-04 -1.38651604e-02\n",
      "  8.15651552e-02  3.82800381e-01  8.57849775e-01  1.00109761e+00\n",
      "  9.69710638e-01  9.30928598e-01  1.00383757e+00  9.64157356e-01\n",
      "  4.49256553e-01 -5.60408259e-03 -3.78319036e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.10620915e-06\n",
      "  4.36410675e-04 -3.95509940e-03 -2.68537241e-02  1.00755014e-01\n",
      "  6.42031710e-01  1.03136838e+00  8.50968614e-01  5.43122379e-01\n",
      "  3.42599738e-01  2.68918777e-01  6.68374643e-01  1.01256958e+00\n",
      "  9.03795598e-01  1.04481574e-01 -1.66424973e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.59875260e-05\n",
      " -3.10606987e-03  7.52456076e-03  1.77539831e-01  7.92890120e-01\n",
      "  9.65626503e-01  4.63166079e-01  6.91720680e-02 -3.64100526e-03\n",
      " -4.12180405e-02 -5.01900656e-02  1.56102907e-01  9.01762651e-01\n",
      "  1.04748346e+00  1.51055252e-01 -2.16044665e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.87012352e-05 -6.40931373e-04\n",
      " -3.23305249e-02  2.78203465e-01  9.36720163e-01  1.04320956e+00\n",
      "  5.98003217e-01 -3.59409041e-03 -2.16751770e-02 -4.81021923e-03\n",
      "  6.16566793e-05 -1.23773318e-02  1.55477482e-01  9.14867477e-01\n",
      "  9.20401348e-01  1.09173902e-01 -1.71058007e-02  0.00000000e+00\n",
      "  0.00000000e+00  1.56250000e-04 -4.27724104e-04 -2.51466503e-02\n",
      "  1.30532561e-01  7.81664862e-01  1.02836583e+00  7.57137601e-01\n",
      "  2.84667194e-01  4.86865128e-03 -3.18688725e-03  0.00000000e+00\n",
      "  8.36492601e-04 -3.70751123e-02  4.52644165e-01  1.03180133e+00\n",
      "  5.39028101e-01 -2.43742611e-03 -4.80290033e-03  0.00000000e+00\n",
      "  0.00000000e+00 -7.03635621e-04 -1.27262443e-02  1.61706648e-01\n",
      "  7.79865383e-01  1.03676705e+00  8.04490400e-01  1.60586724e-01\n",
      " -1.38173339e-02  2.14879493e-03 -2.12622549e-04  2.04248366e-04\n",
      " -6.85907627e-03  4.31712963e-04  7.20680947e-01  8.48136063e-01\n",
      "  1.51383408e-01 -2.28404366e-02  1.98971950e-04  0.00000000e+00\n",
      "  0.00000000e+00 -9.40410539e-03  3.74520505e-02  6.94389110e-01\n",
      "  1.02844844e+00  1.01648066e+00  8.80488426e-01  3.92123945e-01\n",
      " -1.74122413e-02 -1.20098039e-04  5.55215142e-05 -2.23907271e-03\n",
      " -2.76068376e-02  3.68645493e-01  9.36411169e-01  4.59006723e-01\n",
      " -4.24701797e-02  1.17356610e-03  1.88929739e-05  0.00000000e+00\n",
      "  0.00000000e+00 -1.93511951e-02  1.29999794e-01  9.79821705e-01\n",
      "  9.41862388e-01  7.75147704e-01  8.73632241e-01  2.12778350e-01\n",
      " -1.72353349e-02  0.00000000e+00  1.09937426e-03 -2.61793751e-02\n",
      "  1.22872879e-01  8.30812662e-01  7.26501773e-01  5.24441863e-02\n",
      " -6.18971913e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.36563862e-03  3.68349741e-02  6.99079299e-01\n",
      "  1.00293583e+00  6.05704402e-01  3.27299224e-01 -3.22099249e-02\n",
      " -4.83053002e-02 -4.34069138e-02 -5.75151144e-02  9.55674190e-02\n",
      "  7.26512627e-01  6.95366966e-01  1.47114481e-01 -1.20048679e-02\n",
      " -3.02798203e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -6.76572712e-04 -6.51415556e-03  1.17339359e-01\n",
      "  4.21948410e-01  9.93210937e-01  8.82013974e-01  7.45758734e-01\n",
      "  7.23874268e-01  7.23341725e-01  7.20020340e-01  8.45324959e-01\n",
      "  8.31859739e-01  6.88831870e-02 -2.77765012e-02  3.59136710e-04\n",
      "  7.14869281e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.53186275e-04  3.17353553e-04 -2.29167177e-02\n",
      " -4.14402914e-03  3.87038450e-01  5.04583435e-01  7.74885876e-01\n",
      "  9.90037446e-01  1.00769478e+00  1.00851440e+00  7.37905042e-01\n",
      "  2.15455291e-01 -2.69624864e-02  1.32506127e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.36366422e-04\n",
      " -2.26031454e-03 -2.51994485e-02 -3.73889910e-02  6.62121228e-02\n",
      "  2.91134498e-01  3.23055726e-01  3.06260315e-01  8.76070942e-02\n",
      " -2.50581917e-02  2.37438725e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  6.20939216e-18  6.72618320e-04 -1.13151411e-02\n",
      " -3.54641066e-02 -3.88214912e-02 -3.71077412e-02 -1.33524928e-02\n",
      "  9.90964718e-04  4.89176960e-05  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print ('The first element of X is: ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED CELL: Sequential model\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential(\n",
    "    [               \n",
    "        ### START CODE HERE ### \n",
    "        tf.keras.Input(shape=(400,)),\n",
    "        Dense(25, activation = 'relu'),\n",
    "        Dense(15, activation = 'relu'),\n",
    "        Dense(10, activation = 'linear')\n",
    "        \n",
    "        \n",
    "        ### END CODE HERE ### \n",
    "    ], name = \"my_model\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - loss: 1.9113\n",
      "Epoch 2/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.6747\n",
      "Epoch 3/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.4247\n",
      "Epoch 4/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.3389\n",
      "Epoch 5/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.2942\n",
      "Epoch 6/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.2643\n",
      "Epoch 7/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.2416\n",
      "Epoch 8/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - loss: 0.2239\n",
      "Epoch 9/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.2087\n",
      "Epoch 10/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 0.1961\n",
      "Epoch 11/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 0.1844\n",
      "Epoch 12/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1737\n",
      "Epoch 13/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.1644\n",
      "Epoch 14/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.1559\n",
      "Epoch 15/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.1479\n",
      "Epoch 16/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.1401\n",
      "Epoch 17/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.1331\n",
      "Epoch 18/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.1263\n",
      "Epoch 19/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.1196\n",
      "Epoch 20/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.1137\n",
      "Epoch 21/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.1082\n",
      "Epoch 22/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.1027\n",
      "Epoch 23/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - loss: 0.0977\n",
      "Epoch 24/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 0.0930\n",
      "Epoch 25/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0888\n",
      "Epoch 26/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.0843\n",
      "Epoch 27/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 0.0808\n",
      "Epoch 28/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.0764\n",
      "Epoch 29/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.0728\n",
      "Epoch 30/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 0.0690\n",
      "Epoch 31/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.0658\n",
      "Epoch 32/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.0623\n",
      "Epoch 33/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0589\n",
      "Epoch 34/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.0554\n",
      "Epoch 35/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0524\n",
      "Epoch 36/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0493\n",
      "Epoch 37/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 0.0461\n",
      "Epoch 38/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.0436\n",
      "Epoch 39/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 0.0409\n",
      "Epoch 40/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.0382\n",
      "Epoch 41/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 0.0358\n",
      "Epoch 42/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0339\n",
      "Epoch 43/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0319\n",
      "Epoch 44/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0296\n",
      "Epoch 45/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.0277\n",
      "Epoch 46/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0260\n",
      "Epoch 47/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 0.0243\n",
      "Epoch 48/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0222\n",
      "Epoch 49/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.0210\n",
      "Epoch 50/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0193\n",
      "Epoch 51/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0176\n",
      "Epoch 52/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 0.0164\n",
      "Epoch 53/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0152\n",
      "Epoch 54/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - loss: 0.0139\n",
      "Epoch 55/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.0129\n",
      "Epoch 56/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.0119\n",
      "Epoch 57/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.0111\n",
      "Epoch 58/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 0.0102\n",
      "Epoch 59/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.0094\n",
      "Epoch 60/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.0088\n",
      "Epoch 61/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 0.0080\n",
      "Epoch 62/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.0075\n",
      "Epoch 63/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.0068\n",
      "Epoch 64/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.0063\n",
      "Epoch 65/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.0059\n",
      "Epoch 66/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 0.0055\n",
      "Epoch 67/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.0050\n",
      "Epoch 68/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 0.0046\n",
      "Epoch 69/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - loss: 0.0043\n",
      "Epoch 70/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 0.0040\n",
      "Epoch 71/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 0.0037\n",
      "Epoch 72/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 0.0034\n",
      "Epoch 73/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.0031\n",
      "Epoch 74/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0029\n",
      "Epoch 75/75\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 0.0027\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X,y,\n",
    "    epochs=75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      " predicting a Two: \n",
      "[[ -6.1932554   8.799      13.805824   -1.9514216 -15.721959  -13.765581\n",
      "   -4.133926    5.4388313  -4.3868923 -12.634244 ]]\n",
      " Largest Prediction index: 2\n"
     ]
    }
   ],
   "source": [
    "image_of_two = X[1015]\n",
    "\n",
    "prediction = model.predict(image_of_two.reshape(1,400))  # prediction\n",
    "\n",
    "print(f\" predicting a Two: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicting a Two. Probability vector: \n",
      "[[2.04886175e-09 6.64609810e-03 9.93122995e-01 1.42468224e-07\n",
      "  1.49021922e-13 1.05412901e-12 1.60645399e-08 2.30815072e-04\n",
      "  1.24740245e-08 3.26759128e-12]]\n",
      "Total of predictions: 1.000\n"
     ]
    }
   ],
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_p}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_p):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[2] 2\n"
     ]
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "random_index = np.random.randint(m)\n",
    "prediction = model.predict(X[random_index].reshape(1,400))\n",
    "prediction_p = tf.nn.softmax(prediction)\n",
    "yhat = np.argmax(prediction_p)\n",
    "print(y[random_index],yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting number: 4\n",
      "tf.Tensor(\n",
      "[[4.8500287e-11 9.0627316e-13 6.0181966e-15 1.1122346e-17 9.9999928e-01\n",
      "  6.4499073e-07 4.1256520e-08 5.4152443e-11 2.9271685e-10 3.8489571e-08]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tiền xử lí ảnh\n",
    "image = cv2.imread(\"testcase1.png\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray_image = gray_image / 255.0\n",
    "gray_image = gray_image.reshape(1, 400)\n",
    "\n",
    "#Dự đoán giá trị\n",
    "prediction = model.predict(gray_image)\n",
    "prediction_p = tf.nn.softmax(prediction)\n",
    "yhat = np.argmax(prediction_p)\n",
    "\n",
    "#Chi tiết kết quả\n",
    "plt.imshow(gray_image.reshape(20, 20), cmap='gray')\n",
    "plt.title(f'Predicting number: {yhat}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f'Predicting number: {yhat}')\n",
    "print(prediction_p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
